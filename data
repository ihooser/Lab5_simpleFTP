Minute paper one:
	In the first lecture of the semester, the most significant thing that I learned was the doubling of the price and the size of devices. This is huge because the smaller the size of the transistor or of the other devices the smaller the entire product will be. The decrease of the price of the devices are also very important for all of the consumers buying it. A good example of this is the personal computer. It originally started out as the size of a room. Now it is much faster, it holds more information and it fits into the palm of a hand. Because more and more people have a computer or a phone this has also increased the amount of IP traffic that is used. As you stated in class the IP traffic will continue to grow by 3X over the next 5 years.
	The biggest question on my mind is, how far can we, as humans, push the limit of how fast and small we can make the devices? Eventually transistors, capacitors, and other element will hit a wall of how small that they can get. This will also be true to the fact that we will only get so far on how fast we can get our devices to go. You did talk about the expectation of how fast a device should work, but what will our expectations change to in the future?

Minute paper two:
	This lecture taught me a lot about how encrypted information is sent. I had no idea how this worked before this lecture. I can see how the importance of having encrypted information being sent. The military needs to be able to do this to keep what they are doing safe and also they need to keep locations and personal safe. If it was easy to intercept information then a lot of bad things can happen. The way that the encryption happens is also very important. If it is believed that the encryption isn’t good enough then you can always add another key and another encryption. This lecture was also the first time that I had heard about DES encrypting. It has a lot of levels for protections and there is no known back door. Another thing that was important in this lecture was that the sampling frequency needs to be twice the frequency that is being sampled.
	The biggest question on my mind right now is the fact that the key to decode the cipher sent through a secured line. How is that line secured? Is it sent through another cipher and has a different key, or is there another special way that this key is sent to the receiving end.

Minute Paper three:
	The lecture today was about the different switching. The first kind is circuit switching. This type is sending out a large continuous stream of data. This only happens after the connection is made. It was originally used with the old phones. There needed to be a direct connection between the two lines for the data to transfer. If they hadn’t connected yet then a busy signal was sent back.  One of the big downfalls of this is the fact that there needed to be a lot of lines strung to connect the different lines. The next kind of switching is message switching. This is similar to circuit except you can send out the data with a computer. Circuit switching is not able to be sent by data. A big difference between the two is that the message is muxed and the circuit is not. By muxing the routing the lines then you can use less transmission lines. This however has the downside that you need to wait for someone else’s message to be sent first, then you will be able to send the message that you want.  The last type is packet switching this takes the message and breaks it down into pieces. Then the pieces are sent out individually through whatever path they want until they reach their destination. Here they are put back together and used. In packet switching there are also two kinds. The first is virtual circuit. This type will hold the data pieces at the end until all have arrived. Then they will display them in the order that they were originally sent. It ends up looking like the circuit switching. The other kind is datagram. With this the data is used as soon as it arrives at the final destination. It will most likely be out of order, but it will start being used faster because you don’t need to wait till all of the data is at the destination.
	The biggest question on my mind is, how much data needs to be sent multiple times in order for the end to get all of the data? I know that some of the data will be lost along the way.

Minute paper four:
	The main topic for the lecture today was about communication. In order for communication between two entities to be possible three things need to be mutually acceptable. This is what is communicated, how is it communicated, and when is it communicated. If these three things aren’t met then there can’t be any communication between the entities. These protocols can be achieved even if the two entities are talking in a different language. The way to do this is to have another step in between. Just like you said in class, a translator can be the communication between two people. The two people that are talking to each other are speaking different languages but they are now understanding each other. With technology this is really important because if two computers are trying to talk to each other and they can’t understand then the miscommunication can brake something bigger. 
	The biggest question on my mind is, where does the encrypting of the data go in the ISO-OSI model? 

Minute paper five:
	Lecture five was a continuation of lecture four. In this lecture was about layered architecture. Each of the layers that the data goes through changes how it is read and the layering problems can add up. It is still important to go down so many layers though in order for the receiving side will be able to fully understand what is actually being sent. While sending the data from one end to the other the data will be encapsulated by headers and footers. These headers and footers are very important. They state where the data is heading and how it should get there.  
The question that I am wondering is, how complex can the layering and architecture get before the end to end communication is unreadable?

Minute paper seven:
	In this lecture we started out continuing with the physical layer. We talked about how satellites are able to transmit data around the world. The period in which they are orbiting is proportional to the radius of their obit to the 3/2. This means that the higher up the satellite the longer it takes to orbit the earth. The Geostationary satellites are the highest up and take up to 24 hours to rotate the earth. But because they are so far away from earth they have a larger line of sight than the medium or low earth satellites.  You only need to have 3 satellites to be able to send data around the world. This means that you don’t need to send as many satellites into space in order to get data sent, but the time window that you are able to send that data is going to be smaller because it takes a third of a day for one of those satellites to orbit overhead. This is why it is good that the orbiting satellites, hubs and other ground satellites can communicate with each other.
	The biggest question on my mind is, how long does these satellites last? When do they need to be replaced because they have broken down so much data can’t be sent clearly anymore? 

Minute Paper eight:
	The big thing we talked about in class was about line coding. There are many types of line coding but the ones that we talked about were NRZ &NRZI with and without Manchester, and other forms like return to zero. The reason that line coding is so important is because a clock signal needs to be recognized when the data is being received at the end of the line. If the code contains a lot of zeros or ones in a row then it is near impossible to know what the clock is or how many ones or zeros are in that series. The return to zero case can be unique because you are also able to send different levels of ones and zeros. This multileveling means that it will be nicer to send the code. By encrypting the one and zero to -2 1 0 1 2s, as an example, you can easily see when the one or zero changes. With an 8B6T the 8 bit groups that are your code is changed to the 6 multilevel code.
	The biggest question that I have is how many levels for the multileveling can you get before it gets too big.

Minuet Paper nine:
	In this lecture we finished up the physical layer. After reviewing the line coding that we talked about in lecture 8, we discussed block coding. This is the kind of coding that takes some data and then translates it into a different set of bits completely. This is done because by representing the specific set of data with this new data the problem of having too many zeros or ones in a line is settled. If set correctly the clock reading the data will be accurate enough to read what is trying to be sent. The other thing that we talked about was with QPSK. This is used because there are a lot of bits being sent along the lines. To speed up the data process by splitting the binary signal and multiplying the signal by a sin or cos wave. Then you add the two signals back together. By doing this you can read the signal bits in one setting. While reading the signal you look at the Ak and Bk from the signal and compare it to the Quadrature Amplitude Modulation. This graph can show what the original binary code should be. If the received signal is too noisy it will be near impossible to read the code, so you will need to make sure that the amount of noise compared to how many bits you are reading in has a good ratio.
	The biggest question that I have is why do you need 5 empty channels in the Digital Subscriber Lines?
Minute paper ten:
	This lecture was about sockets. Sockets are part of having a wireless connection between two different devices. It is an important part of the wireless connection because it contains an address that uses the IP-address and the port number that the data is being sent to. This socket will be containing a datagram. This datagram will contain port numbers, a checksum and the data that was being sent. The socket is in between the client and the server. It helps connect the two for communication. Without the socket the communication could become more distorted and less reliable. The client server connection is an important thing to keep connected. This is because the client and the server allow the other one to work properly. If one of them goes out the other might run differently and effect some of the other clients.
	My question is should a socket always be used be used or only in important set-ups.

Minute paper eleven:
	This lecture was about the Logical link layer. This is the level right above the physical layer. It deals with identifying frame boundaries, error detection and error correction. In this layer you can see the header body and some other framing. The character framing is very important because its first set of characters shows when the receiver needs to start paying attention. It will also have a set character that will tell the receiver when to stop looking at the data. This can be a problem because if the starting or ending character is seen in the data then the receiver will assume that the data is done and end up discarding it. There are a few different ways to get through this. Such as using parity bits, Polynomial codes, checksums, and lengths. All this so that it is affirmed that the data has been sent successfully.
	The question on my mind is how good is the devices that we use today? Have they lowered the bit error probability to almost nothing or is there still some good room to improve.

Minute paper twelve:
	In this lecture we started out by talking about bit error probability. This is based on the number of bits used and some other things. Because binary is at the most basics of communication, if the bits are being sent incorrectly it can cause some really big errors. One of the ways to prevent these errors or at least know if the errors are happening is to use polynomial arithmetic. This transforms the binary representation into a polynomial to the Lth power. Then by doing some division you are able to send a more reliable signal. When the signal is received there is a better chance that it is what is wanted or know if the signal is an error. This process is called polynomial coding.
	The biggest question on my mind is how is it know if the check is sent incorrectly? If the data is incorrect then the check tells that. What if the check is wrong?

Minute paper fifteen:
	This lecture brought together the last few lectures and some of the HW together. We talked about hamming distance. This takes the data that we are sending and adds error detecting to the end of it by following some steps you are able to discover how many bits are incorrect and which bits those are. This is great to have because the biggest problem with sending data is finding out what bits are wrong, if there are any that are incorrect. By having hamming the confidence that you can have that the data was sent correctly will greatly increase. The error correction can also use ARQ and FEC to check to see what error are there. These error corrections can have a few different processes to do this.
	The biggest question that I have is, what is making sure that the error checking at the end of the hamming is the correct set of bits? So what is checking the checker?

Minute paper sixteen:
	In this lecture we started to talk about transmitting data in a different way than from the last lectures. It started by reviewing the look at sending data from point a to point b then receiving an acknowledgment bit. Then we discussed the automatic repeat request. With this comes into effect the time out. This time out needs to be set so that there is plenty of time for the data to get to the destination and then send the acknowledgment back. If it is too short then there will never be enough time for the acknowledgment to return and every bit of data sent will appear lost. If the timeout is too long then you are simply making the connection too slow, and wasting time. WE then talked about the stop and wait model. In this model you can send a frame then wait for the acknowledgment. When it gets back you send the next frame. The next type we talked about is the sliding window. This is when you continuously send frames until you receive an acknowledgement. This acknowledgment will tell if you need to resend the previous frames or if you can send the next few.
	The biggest question that I have is how many times will frames be sent and be lost before it stops working and reports an error.

Minute paper seventeen:
	This lecture was done by a guest speaker. This speaker is doing a project that works similar to Seri or to google home. Her idea is different in the fact that all the programming will be open source. She is also building this project of hers from scratch. It will also be a lot more privet than what Seri or google home is. It will eventually be able to do whatever someone says and then do it. This is her biggest problem at the moment. Her system is translation natural language to a program code. This code is then able to run through a few different locations that will do what the user wanted. It will also have the possibility to share different information between different users. This is good because it allows people to share and still connect with others. If a user is requesting to override a lock or request information from a different user it will send the request and wait till a response is made. This will allow sharing but keep privacy at the same time.
	My biggest question is, her biggest problems have already been solved by others. Why didn’t she try and convince them to change what they are doing right now to what she wants. It would be faster.
Minute paper eighteen 
	In this lecture we started out talking about sending information using TCP. With TCP it sends data in sections rather than the full thing at one time. This allows it to catch data that gets lost early on. If the missing data is caught early then the data transfer will move quicker and easier. The other thing that we talked about was sliding window and the TCP header. The header contains a lot of information that the receiver needs to know from the sender. The last thing that we talked about was the concept of control flow. This control flow is used because throughout the process of sending data from the sender to the receiver there will be different sections that are running at different processing speeds and different data rates.  It is the same as cars entering onto a highway or a back road. The size of the data rate is the size of the high way. Controlling the flow is used to separate the data packets and press them closer together or force them farther apart.
	My question is, if the header is telling information about the data being sent. If it is sent wrong then does it reject the entire data packed because of it?

Minute paper nineteen
	This lecture started out talking about flow control. The flow control is needed because from point a to point b there will be different data rates. These data rates will change the time distance between the packets. Then when the data packets get to receiver the data packets will be spread apart. This distance is important to keep because it will be used for the acknowledgement. The acknowledgement packets sent back with the time distance that the original data had. This keeps the congestion down so timeout can be set correctly. The next thing that we talked about w2as the congestion through the internet. This congestion has a point in which it will crash. At height usage points most users will refresh pages and do other things such that make all the packets sent to them useless. All of these packets make the internet more congested and run slower. It then will make it so that the internet is needed to be closed and reset. This is what it means when the internet crashes.
